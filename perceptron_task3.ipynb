{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d23477a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import tensorflow as tf 500 и 200 нейронов\n",
    "#from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.datasets import load_iris, load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.datasets import fetch_openml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7da74455",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "97696447",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiLayerPerceptron:\n",
    "  def __init__(self, input_size, hidden_sizes, output_size, learning_rate=0.01, epochs=1000):\n",
    "    self.learning_rate = learning_rate\n",
    "    self.epochs = epochs\n",
    "    self.input_size = input_size\n",
    "    self.hidden_sizes = hidden_sizes # Список с количеством сумматоров в каждом скрытом слое\n",
    "    self.output_size = output_size\n",
    "\n",
    "    # Инициализация весов и смещений\n",
    "    self.weights = []\n",
    "    self.biases = []\n",
    "    \n",
    "    # Начальное количество входов\n",
    "    layer_input_size = input_size\n",
    "    \n",
    "    for hidden_size in hidden_sizes:\n",
    "      self.weights.append(np.random.uniform(size=(layer_input_size, hidden_size), low=-0.5, high=0.5))\n",
    "      self.biases.append(np.random.uniform(low=-0.5, high=0.5, size=(hidden_size,)))\n",
    "      layer_input_size = hidden_size\n",
    "    \n",
    "    self.weights.append(np.random.uniform(size=(layer_input_size, output_size), low=-0.5, high=0.5))\n",
    "    self.biases.append(np.random.uniform(low=-0.5, high=0.5, size=(output_size,)))\n",
    "\n",
    "  def activation_function(self, net_input):\n",
    "    return 1 / (1 + np.exp(-net_input))\n",
    "\n",
    "  def fit(self, features, targets):\n",
    "    n_examples = features.shape[0]\n",
    "    \n",
    "    for _ in range(self.epochs):\n",
    "      for example_index, example_features in enumerate(features):\n",
    "        # Прямое распространение\n",
    "        activations = [example_features]\n",
    "        for weight, bias in zip(self.weights, self.biases):\n",
    "          net_input = np.dot(activations[-1], weight) + bias\n",
    "          activation = self.activation_function(net_input)\n",
    "          activations.append(activation)\n",
    "\n",
    "        # Обработка ошибок (обратное распространение)\n",
    "        error = targets[example_index] - activations[-1]\n",
    "        for i in reversed(range(len(self.weights))):\n",
    "          output = activations[i + 1]\n",
    "          delta = error * output * (1 - output) # Производная сигмоиды\n",
    "          if i > 0: # Если это не последний слой, мы должны учитывать предыдущее состояние\n",
    "            error = np.dot(delta, self.weights[i].T)\n",
    "          self.weights[i] += self.learning_rate * np.outer(activations[i], delta)\n",
    "          self.biases[i] += self.learning_rate * delta\n",
    "\n",
    "  def predict(self, features):\n",
    "    for weight, bias in zip(self.weights, self.biases):\n",
    "      features = self.activation_function(np.dot(features, weight) + bias)\n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7998de64",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = fetch_openml('mnist_784')\n",
    "X, y = mnist['data'], mnist['target'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a69e448c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "781f4622",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [28]\u001b[0m, in \u001b[0;36m<cell line: 17>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Моделирование\u001b[39;00m\n\u001b[0;32m     16\u001b[0m mlp \u001b[38;5;241m=\u001b[39m MultiLayerPerceptron(input_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m784\u001b[39m, hidden_sizes\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m128\u001b[39m, \u001b[38;5;241m64\u001b[39m], output_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n\u001b[1;32m---> 17\u001b[0m \u001b[43mmlp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Прогноз\u001b[39;00m\n\u001b[0;32m     20\u001b[0m y_pred_train \u001b[38;5;241m=\u001b[39m mlp\u001b[38;5;241m.\u001b[39mpredict(X_train)\n",
      "Input \u001b[1;32mIn [8]\u001b[0m, in \u001b[0;36mMultiLayerPerceptron.fit\u001b[1;34m(self, features, targets)\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m: \u001b[38;5;66;03m# Если это не последний слой, мы должны учитывать предыдущее состояние\u001b[39;00m\n\u001b[0;32m     45\u001b[0m   error \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(delta, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights[i]\u001b[38;5;241m.\u001b[39mT)\n\u001b[1;32m---> 46\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights[i] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearning_rate\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mouter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mactivations\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdelta\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbiases[i] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlearning_rate \u001b[38;5;241m*\u001b[39m delta\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Предобработка данных\n",
    "X /= 255.0 # Нормализация\n",
    "\n",
    "# Одна горячая кодировка меток\n",
    "encoder = OneHotEncoder()\n",
    "y_encoded = encoder.fit_transform(y.values.reshape(-1, 1))\n",
    "\n",
    "# Разделение на обучающую и тестовую выборки\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
    "   \n",
    "X_train = X_train.values\n",
    "y_train = y_train.toarray()\n",
    "   \n",
    "\n",
    "# Моделирование\n",
    "mlp = MultiLayerPerceptron(input_size=784, hidden_sizes=[128, 64], output_size=10)\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "# Прогноз\n",
    "y_pred_train = mlp.predict(X_train)\n",
    "y_pred_test = mlp.predict(X_test)\n",
    "\n",
    "# Оценка точности\n",
    "train_accuracy = accuracy_score(np.argmax(y_train, axis=1), np.argmax(y_pred_train, axis=1))\n",
    "test_accuracy = accuracy_score(np.argmax(y_test, axis=1), np.argmax(y_pred_test, axis=1))\n",
    "\n",
    "print(f\"Train accuracy: {train_accuracy:.2f}\")\n",
    "print(f\"Test accuracy: {test_accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1982ac79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обучение модели SVC\n",
    "svc_pipeline = make_pipeline(StandardScaler(), SVC(C=1.0, gamma='scale'))\n",
    "svc_pipeline.fit(X_train, y_train.argmax(axis=1))\n",
    "\n",
    "# Прогноз\n",
    "svc_predictions = svc_pipeline.predict(X_test)\n",
    "\n",
    "# Оценка точности\n",
    "svc_accuracy = accuracy_score(y_test.argmax(axis=1), svc_predictions)\n",
    "print(f\"SVC test accuracy: {svc_accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee95b046",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b9ae436",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
